\section{Linear Algebra II}

\begin{itemize}

    \item Let's review matrix multiplication once before moving forward:
    \begin{align*}
        \bm{A} = 
        \underset{2 \times 3}{\begin{bmatrix}
            1 & 2 & -3 \\
            4 & 0 & -2   
        \end{bmatrix}},
        \; \; \; 
        \bm{B} =
        \underset{3 \times 2}{\begin{bmatrix}
            3 & 1 \\
            2 & 4 \\
            -1 & 5
        \end{bmatrix}}
    \end{align*}
    
    \item The dimensions of the product of these two matrices is the outside dimensions:
    \begin{align*}
        \bm{A}\bm{B} & = (\bm{2} \times 3) \cdot (3 \times \bm{2}) = 2 \times 2 \\ 
        \bm{B}\bm{A} & = (\bm{3} \times 2) \cdot (2 \times \bm{3}) = 3 \times 3
    \end{align*}

    \item We know we can multiply the two together in either direction because the inner dimensions match in either order.
    \begin{align*}
        \begin{bmatrix}
            1 & 2 & -3 \\
            4 & 0 & 2
        \end{bmatrix}
        \begin{bmatrix}
            3 & 1 \\
            2 & 4 \\
            -1 & 5
        \end{bmatrix}
        = 
        \begin{bmatrix}
            3 + 4 + 3 & 1 + 8 -15 \\
            12 + 0 -2 & 4 + 0 + 10
        \end{bmatrix}
        = 
        \begin{bmatrix}
            10 & -6 \\
            10 & 14
        \end{bmatrix}
    \end{align*}

    \item One more example:
    \begin{align*}
        \begin{bmatrix}
            1 & 2 & 1 \\
            0 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            4 & 3 \\
            7 & 8 \\
            1 & 2
        \end{bmatrix} 
        = 
        \begin{bmatrix}
            4 + 14 + 1 & 3 + 16 + 2 \\
            0 + 7 + 1 & 0 + 8 + 2 
        \end{bmatrix}
        = 
        \begin{bmatrix}
            19 & 21 \\
            8 & 10
        \end{bmatrix}
    \end{align*}
\end{itemize}


\subsection{Matrix Representation of Systems of Equations}

\begin{itemize}
    \item Take this system of equations:
    \begin{align*}
        a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n & = b_1 \\
        \vdots & \\
        a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n & = b_m 
    \end{align*}

    \item Or in matrix form:
    \begin{align*}
        \underset{m \times n}{
            \begin{bmatrix}
                a_{11} & a_{12} & ... & a_{1n} \\
                \vdots & \\
                a_{m1} & a_{m2} & ... & a_{mn}
            \end{bmatrix}
        }
        \underset{n \times 1}{
            \begin{bmatrix}
                x_1 \\
                x_2 \\
                \vdots \\
                x_n
            \end{bmatrix}
        }
        =
        \underset{m \times 1}{
            \begin{bmatrix}
                b_1 \\
                b_2 \\
                \vdots \\
                b_m
            \end{bmatrix}
        }
    \end{align*}

    \item Ex:
    \begin{align*}
            2x_1 + 3x_2 - 1x_3 & = 7 \\
            4x_1 + 5x_2 + 6x_3 & = 8 \\
            -1x_1 + 2x_2 + 1x_3 & = 9    
    \end{align*}
    \vspace{-3.5em}
    \begin{center}
        $\Downarrow$
    \end{center}
    \vspace{-2em}
    \begin{align*}
        \underset{A}{
            \begin{bmatrix}
                2 & 3 & -1 \\
                4 & 5 & 6 \\
                -1 & 2 & 1
            \end{bmatrix}
        }
        \underset{X}{
            \begin{bmatrix}
                x_1 \\
                x_2 \\
                x_3
            \end{bmatrix}
        }
        =
        \underset{b}{
            \begin{bmatrix}
                7 \\
                8 \\
                9
            \end{bmatrix}
        }
    \end{align*}
\end{itemize}


\subsection{Linear Dependence and Independence}

\begin{itemize}
    \item The \textbf{span} of a vector is all of its linear combinations. I.e. $c\begin{bmatrix} 2 \\ 3 \end{bmatrix} \forall \, c$.
    \begin{itemize}
        \item On linear combinations: the linear combination of 
        \vspace{-1em}
        \begin{align*}
            2x \\
            3x
        \end{align*}

        \vspace{-2em}
        is $x \begin{bmatrix}
            2 \\ 3 
        \end{bmatrix}$
    \end{itemize}
    \item If one vector falls in the span of another vector then the two are \textbf{linearly dependent}. There is no new information in the second vector.
    \begin{itemize}
        \item $ \begin{bmatrix} 2 \\ 3 \end{bmatrix}$ and 
            $\begin{bmatrix} 4 \\ 6 \end{bmatrix}$ are linearly dependent. The second is the first times 2. 
    \end{itemize}
    \item If one vector \emph{does not} fall in the span of another vector, then the two are \textbf{linearly independent}.
    \begin{itemize}
        \item $\begin{bmatrix} 7 \\ 0\end{bmatrix}$ and 
        $\begin{bmatrix} 0 \\ -1 \end{bmatrix}$ are linearly independent. One cannot be represented as a linear combination of the other.
    \end{itemize}
    \item If we were to draw each item in the vector set, then we are interested in whether or not the overall span of a set changes when a vector is added or removed. 
    %\item Formally, a vector set is linearly independent if, for a set $S = \{\bm{v}_1, \bm{v}_2, ..., \bm{v}_n\}$ the only solution to $c_1\bm{v}_1 + c_2\bm{v}_2 + ... + c_n\bm{v}_n = 0$ is $c_1 = c_2 = ... = c_n = 0$.
    %\begin{itemize}
    %    \item If, on the other hand, at least one solution includes a non-zero scalar, then the vector set is linearly dependent.
    %\end{itemize}
\end{itemize}

\subsection{Properties of Matrix Operators}

\begin{itemize}
    
    \item Matrix Addition
    \begin{itemize}
        \item If $\bm{A}$ and $\bm{B}$ are both the same size ($m \times n$):
        \begin{enumerate}
            \item $\bm{A} + \bm{B} = \bm{B} + \bm{A}$
            \item $\bm{A} + (\bm{B} + \bm{C}) = (\bm{A} + \bm{B}) + \bm{C}$
            \item Additive Inverse: $\bm{A} + (- \bm{A}) = 0_{m \times n}$  
        \end{enumerate}
    \end{itemize}

    \item Matrix Multiplication:
    \begin{itemize}
        \item If $\bm{A}, \bm{B}, \bm{C}$ are conformable:
        \begin{enumerate}
            \item $\bm{A}(\bm{B}\bm{C}) = (\bm{A}\bm{B})\bm{C}$
            \item $\bm{I}\bm{A} = \bm{A}\bm{I} = \bm{A}$
            \begin{itemize}
                \item Where $\bm{I}$ is an identity matrix, e.g. $\bm{I}_{3 \times 3} = 
                \begin{bmatrix}
                    1 & 0 & 0 \\
                    0 & 1 & 0 \\
                    0 & 0 & 1    
                \end{bmatrix}$
            \end{itemize}
            \item $\bm{A}(\bm{B} + \bm{C}) = \bm{AB} + \bm{AC} \neq \bm{BA} + \bm{CA}$ because order matters
        \end{enumerate}
    \end{itemize}

    \item Matrix Exponents
    \begin{enumerate}
        \item $\bm{A}^p \cdot \bm{A}^q = \bm{A}^{p + q}$
        \item $(\bm{A}^p)^q = \bm{A}^{pq}$ 
        \item $(\bm{A}\bm{B})^p \neq \bm{A}^p\bm{B}^p$ unless $\bm{AB} = \bm{BA}$
    \end{enumerate}
    
    \item Scalar Multiplication; $\bm{A}, \bm{B}$ are matrices and $r, s$ are scalars:
    \begin{enumerate}
        \item $r(s\bm{A}) = (rs\bm{A})$
        \item $(r + s)\bm{A} = r\bm{A} + s\bm{A}$
        \item $r(\bm{A} + \bm{B}) = r\bm{A} + r\bm{B}$
        \item $A(r\bm{B}) = r\bm{A}\bm{B} = \bm{A}\bm{B}r$
    \end{enumerate}

    \item Matrix Transposition
    \begin{enumerate}
        \item $(\bm{A}^T)^T = \bm{A}$
        \item $(\bm{A} + \bm{B})^T = \bm{A}^T + \bm{B}^T$
        \item $(\bm{AB})^T = \bm{B}^T\bm{A}^T$
        \item $(rA)^T = r(A^T)$
    \end{enumerate}

    \item Symmetric Matrix: A square matrix is symmetric if $\bm{A}^T = \bm{A}$
    \begin{itemize}
        \item Ex: $
            \begin{bmatrix}
                1 & 2 & 3 \\
                2 & 4 & 1 \\
                3 & 1 & 5
            \end{bmatrix}
            $
    \end{itemize} 
\end{itemize}


\subsection{Idempotent Matrices}

\begin{itemize}
    \item A matrix, $\bm{A}$, is idempotent if $\bm{AA} = \bm{A}$. Multiplying the matrix by itself returns the original matrix.
\end{itemize}


\subsection{Reduced Row/Row Echelon Form and Solving Linear Systems of Equations Gauss-Jordan Reduction/Elimination}


\begin{itemize}
    \item We can use a matrix to represent a system of equations:
    \begin{align*}
        a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n & = b_1 \\
        a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n & = b_2 \\
                                                & \vdots \\
        a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n & = b_m 
    \end{align*}    
    \item Rewritten as an \textbf{augmented matrix}:
    
    \begin{center}
    $\begin{bmatrix}[cccc|c]
        a_{11} & a_{12} & ... & a_{1n} & b_1 \\
        a_{21} & a_{22} & ... & a_{2n} & b_2 \\
        \vdots &        & \ddots & \vdots & \vdots \\
        a_{m1} & a_{m2} & ... & a_{mn} & b_m
    \end{bmatrix}$
    \end{center} 

    \item To solve for a system of equations, we often want to translate a matrix into \textbf{row echelon} or \textbf{reduced row echelon} form.  What conditions describe a matrix in row echelon and reduced row echelon form. The conditions are:
    \begin{enumerate}
        \item If any rows are zeros, then they are below nonzero rows (include at least one nonzero element): 
            
        $\begin{bmatrix}[ccc|c]
            1 & 2 & 3 & 7 \\
            0 & 0 & 0 & 0 
        \end{bmatrix}$
        
        \item The first non-zero entry in any row is 1 (except all zero row).
            
        $\begin{bmatrix}[ccc|c]
            0 & 1 & 3 & 7 \\
            0 & 0 & 0 & 0 
        \end{bmatrix}$
            
        \item For each non-zero row the leading 1 is to the right of each 1 in the row above.
            
        $\begin{bmatrix}[ccc|c]
            1 & 0 & 3 & 7 \\
            0 & 1 & 4 & 0 \\
            0 & 0 & 1 & 2 
        \end{bmatrix}$
            
        \item \textbf{Reduced row-echelon form}: makes the solution to a system of equations obvious. Below $x_1 = 7, x_2 = 0, x_3 = 2$
        
        $\begin{bmatrix}[ccc|c]
            1 & 0 & 0 & 7 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 2
        \end{bmatrix}$

    \end{enumerate}

    \item Transforming a matrix into row echelon and reduced row echelon form is referred to as \textbf{Gauss-Jordan elimination}. We do so through \textbf{elementary row operators}:
    
    \begin{itemize}
        \item Multiplying a row by a constant
        \begin{itemize}
            \item Remember, the matrix is a system of equations. So we're just multiplying both sides of an equation.
        \end{itemize}
        \item Adding/subtracting rows
        \item Interchanging rows
    \end{itemize}
    
    \item Example:
    \begin{align*}
        1x_1 + 2x_2 + 4x_3 & = 3 \\
        2x_1 + 1x_2 + 3x_3 & = 2 \\
        1x_1 + 2x_2 + 2x_3 & = 3
    \end{align*}

    \begin{itemize}
        \item As an augmented matrix:

        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 4 & 3 \\
                2 & 1 & 3 & 2 \\
                1 & -2 & 2 & 3
            \end{bmatrix}$    
        \end{center}

        \item Add $-2r1$ to $r2$ and $-1r1$ to $r3$

        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 4 & 3 \\
                0 & -3 & -5 & -4 \\
                0 & -4 & -2 & 0
            \end{bmatrix}$    
        \end{center}

        \item $r3 \times -\frac{1}{4}$ and interchange $r2$ and $r3$
        
        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 4 & 3 \\
                0 & 1 & 1/2 & 0 \\
                0 & -3 & -5 & -4
            \end{bmatrix}$
        \end{center}

        \item Add $3r2$ to $r3$ 

        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 4 & 3 \\
                0 & 1 & 1/2 & 0 \\
                0 & 0 & -7/2 & -4
            \end{bmatrix}$
        \end{center}

        \item Multiply $r3$ by $-\frac{2}{7}$

        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 4 & 3 \\
                0 & 1 & 1/2 & 0 \\
                0 & 0 & 1 & 8/7
            \end{bmatrix}$
        \end{center}

        \item Subtract $4r3$ from $r1$ and subtract $\frac{1}{2}r3$ from $r2$
        
        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 2 & 0 & -11/7 \\
                0 & 1 & 0 & -4/7 \\
                0 & 0 & 1 & 8/7
            \end{bmatrix}$
        \end{center}

        \item Subtract $2r2$ from $r1$
    
        \begin{center}
            $\begin{bmatrix}[ccc|c]
                1 & 0 & 0 & -3/7 \\
                0 & 1 & 0 & -4/7 \\
                0 & 0 & 1 & 8/7
            \end{bmatrix}$
        \end{center}

        \item $x_1 = -\frac{3}{7}, x_2 = -\frac{4}{7}, x_3 = \frac{8}{7}$ 
        \item Or: $\text{I}_3X = \begin{bmatrix}
            -3/7 \\ -4/7 \\ 8/7
        \end{bmatrix}$

    \end{itemize}
\end{itemize}